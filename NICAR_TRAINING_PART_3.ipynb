{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFiF4sctp1W7"
   },
   "source": [
    "# Data analysis with Python — PART 3\n",
    "\n",
    "## Grouping and Merging (and a few formulas)\n",
    "\n",
    "You've learned how to import files, filter and sort. Now you're going to learn how to aggregate, use formulas and merge tables. \n",
    "\n",
    "<b>The objective: Find which gubernatorial candidate won each precinct, and if any majority-Republican precincts voted for Katie Hobbs, the democrat candidate.</b> \n",
    "\n",
    "Precincts can be interesting to see how certain areas of the county swung. Specifically, we've used precinct-level data to identify areas that had [voted for Trump in 2016 but flipped for Biden in 2020.](https://www.azcentral.com/story/news/politics/elections/2020/11/18/how-did-president-elect-joe-biden-win-arizona-map-maricopa-county-votes-reveals-one-key-path-victory/6328880002/) Or, more recently, we've used precinct-level data to identify areas that are [Republican strongholds that didn't come out for Kari Lake in the numbers that she needed.](https://www.azcentral.com/story/news/politics/elections/2022/11/23/republican-voters-fueled-arizona-democratic-wins-in-midterms/69671685007/) \n",
    "\n",
    "But as you've probably come to realize, the structure of our election data doesn't allow us to easily see who won which race in each precinct, and what percent of the vote each candidate got. Our election file also doesn't have any party registration data in it. \n",
    "\n",
    "Start by importing pandas and the elections file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "fCZ4SJVapve0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYAI178PqBJ2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('elections_03_02_23.csv',\n",
    "                 dtype={'i_contest_id': str, 'candidate_id': str})                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_-8I_YOqPMf"
   },
   "source": [
    "# Clean the data first \n",
    "\n",
    "The county excludes certain candidate types when it is calculating the total votes per race. By selecting for only candidates with an \"R\" OR \"Q\" designation in the candidate_type field, we are following their method for including only named candidates and qualified write-ins. \n",
    "\n",
    "The filter below overwrites our dataframe — df — so that it only included either Q candidates OR R candidates. The pipe symbol ( | ) means \"or.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "vCQa3qfnqIEl"
   },
   "outputs": [],
   "source": [
    "df = df[(df['candidate_type'] == 'Q') | (df['candidate_type'] == 'R')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remember those precincts with zero voters? Let's get rid of those as well. Write that filter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Govenor Race \n",
    "Write a filter that creates a table that includes only the Governor contest. I've called it \"gov\" here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the total votes per precinct\n",
    "\n",
    "The winner per precinct is going to be calculated by dividing a candidate's votes over the total number of votes cast in that contest. To get the total number of votes cast, we'll need to use * drumroll * a GroupBy.\n",
    "\n",
    "Think of a GroupBy like a pivot table in Excel. In Excel, you drag the column that you want to group by into rows, and the column that you want to measure into Values.\n",
    "\n",
    "With pandas, you'll be dropping the column you want to group by in parentheses, and the column you want to measure into brackets, followed by the math you want to do on that column.  \n",
    "\n",
    "The example below sums votes for each precinct.\n",
    "\n",
    "If for whatever reason you wanted to get an average number of votes each precinct reported per contest, you would write .mean() instead. If you wanted to get the maximum number of votes any precinct reported for each contest, you'd write .max(). Same idea for .min() \n",
    "\n",
    "The main idea here is that you can use a groupby to do a wide variety of math things on any given column and the syntax is almost always going to be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov_total = gov.groupby('precinct_name')['votes'].sum().to_frame(name = 'total_votes').reset_index()\n",
    "gov_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nuckb-IyueGR"
   },
   "source": [
    "OK, but what's all the stuff after the .sum() command? \n",
    "\n",
    ".to_frame(name = 'total_votes') is optional. This is simply here if I wish to rename my column header in my groupby. If you run the groupby command followed only by .reset_index(), the computer will retain your original column header. And maybe that's fine, and you want that. But sometimes you won't want that. In this case, I want to make the distinction that my vote column is a total of all votes, so I'm being extra specific. \n",
    "\n",
    ".reset_index() is not optional, if you have any hope to use your groupby again. Simply running the groupby command without results in a print out that you cannot use as a table. Run the code below and you'll see what I mean. \n",
    "\n",
    "Resetting your index allows the computer to make a new table that you can call upon just like when you call upon the original dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdbPhiHivpSh",
    "outputId": "b7787074-c6f9-408d-e1bd-90dd541881fa"
   },
   "outputs": [],
   "source": [
    "test = gov.groupby('precinct_name')['votes'].sum()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate only columns we care about\n",
    "\n",
    "This database is massive. There are a lot of columns that we don't need that might just end up confusing us. If our objective is to find out how many votes each candidate got relative to the total votes, lets' just grab the bare minimum we need to do achieve that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a subset of the original dataframe that just contains candidate_name, votes and precinct_name\n",
    "#any time you want to create a truncated version of your dataset, you can write the name of the table you want to truncate,\n",
    "#follow with brackets, and then put your desired column names into single or double quotes. \n",
    "#In this example I have named my new table gov_cand_votes\n",
    "\n",
    "#Just run this code\n",
    "gov_cand_votes = gov[['candidate_name', 'precinct_name', 'votes']]\n",
    "gov_cand_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAeUVu7I21Dd"
   },
   "source": [
    "## Merging\n",
    "Ok. So we have two separate dataframes. One is our groupby that sums the total votes per precinct. The other is a slice of our original dataframe that tells us how many votes each candidate got. How do we calculate percentages? These tables alone aren't super helpful. But combining them is how we answer one of our questions. \n",
    "\n",
    "Enter: Merging. \n",
    "\n",
    "Let me first start by stressing that there are various ways to merge different datasets. In the future, for example, you may find yourself needing to merge data based on location values (like lat/long) — that's called a spatial join, and it requires a different toolkit and approach than what we'll be using today.\n",
    "\n",
    "Today, we're showing you how to merge on a common column. \n",
    "\n",
    "([Here's a little illustration explaining what, exactly, we're doing](https://jamboard.google.com/d/1P3EDbX9YlOHig6CtDNhKISTAKcf8yCc8F5YT0D-xK0E/edit?usp=sharing))\n",
    "\n",
    "Our two datasets have a common column: precinct_name. \n",
    "\n",
    "In order for this to work, the matching columns in both datasets need to be the same datatype. If precinct_name were a string in one file and an integer in the other, we would get an error message. (This is one of the reasons why it's important to specify dtypes upon import.) \n",
    "\n",
    "You have several options for column-matching merges, depending on your desired outcome. [This page gives a good explanation of left, right, inner and outer merges.](https://www.analyticsvidhya.com/blog/2020/02/joins-in-pandas-master-the-different-types-of-joins-in-python/#:~:text=Full%20Join%2C%20also%20known%20as,that%20lacks%20a%20matching%20row.) \n",
    "\n",
    "We're going to do an inner merge, which just means that only values contained in both datasets will survive the merge. If I have precinct A in one file, but it doesn't appear in the other, then the file resulting from my merge will not have precinct A in it. \n",
    "\n",
    "(If I wanted to keep precinct A regardless of its appearance in the other dataset, I'd use a left or right merge. Refer to the page I linked to about this.) \n",
    "\n",
    "Here's the syntax for an inner merge where the column names that you're merging on are the same — it's a nice, short line:\n",
    "\n",
    "    output_data = pd.merge(table_1,table_2)\n",
    "\n",
    "If your column names were different (or you wanted to do a left or a right merge), you'd need a little more:\n",
    "\n",
    "    output_data = table_1.merge(table_2, left_on='table_1_column', \n",
    "    right_on='table_2_column',how=\"inner\")\n",
    "\n",
    "Here's how this works:\n",
    "-  Your left dataset is considered the one to the left of .merge \n",
    "-  Your right dataset is considered the one to the right of the (\n",
    "-  *left_on=''* will correspond to the merge column name in your left dataset\n",
    "-  *right_on=''* will correspond to the merge column name on the right.\n",
    "-  *how='inner'* is the type of join we want. If you wanted to keep everything in the left dataset, regardless if it appeared in the right, you'd write 'left' there.\n",
    "\n",
    "Merges are complicated. It's totally okay if you're like \"left? right? huh????\" right now! We're happy to answer any questions you might have about merges. \n",
    "\n",
    "Try to write a merge on your own that brings together our two tables, using either of those two sample code lines above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "xy8-Rrvr1H8j",
    "outputId": "857369a7-4eff-4072-886f-80bde290e684"
   },
   "outputs": [],
   "source": [
    "#I'm calling your merge plv, short for precinct-level votes\n",
    "plv = \n",
    "plv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "062jbDVlRTB8"
   },
   "source": [
    "You should now have in the same table the number of votes each candidate got in each precinct AND the total votes for the Govenor race coming from that precinct. So you could do the math to determine the percent of votes. We'll do that next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOxPLGC0-cgH"
   },
   "source": [
    "# Determining winners\n",
    "\n",
    "Now it's time to expand that table and make the computer do some math for us! We'll be adding columns to our table. Any time you want to create a new column, you will name the the dataframe that you're using, open brackets, and put your desired column name in quotes in those brackets. \n",
    "\n",
    "Follow it with what you want to be in that column. In this case, we are saying that our new column = votes divided by total votes. Yes, you have to specify each time which dataframe you're dealing with. \n",
    "\n",
    "The code below assumes you named named your summed votes from your groupby above 'total_votes'. If you called it something else, replace 'total_votes' with whatever you called it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FVVE2EKB2FMj",
    "outputId": "d67bce2c-bbd1-4eb0-b820-796fc0c9c8dc"
   },
   "outputs": [],
   "source": [
    "plv['perc_of_votes'] = plv['votes']/plv['total_votes']\n",
    "plv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T46AkLEMAFk9"
   },
   "source": [
    "But we still can't see who won each precinct, right? We'd have to eyeball it. Let's do one more groupby - but this time we're going to drop the results of the groupby into a column within our database. \n",
    "\n",
    "This will look a little different from our first two group bys.\n",
    "\n",
    "Instead of creating a new dataframe for this groupby, we're creating a new column within our preexisting dataframe. We do that just as we did above: write the name of the dataframe you want to drop your new column, and the name of your new column. (In brackets, in quotes.) \n",
    "\n",
    "To determine first place, second place, third place, etc. we will use .rank(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "vw2wK6Mc2GLj",
    "outputId": "ea7bfe65-fe93-4865-b493-ee78082d31f3"
   },
   "outputs": [],
   "source": [
    "plv[\"rank\"] = plv.groupby(\"precinct_name\")[\"votes\"].rank(method=\"dense\", ascending=False)\n",
    "plv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9cWrZ9oCkSQ"
   },
   "source": [
    "This code groups precincts and then calculates each vote tally's place in that precinct. Because we specified ascending = False, our largest vote tally will be given a 1.\n",
    "\n",
    "...bUt wHaT aBoUt TiEs? \n",
    "\n",
    "If you are wondering that, good for you. Though it seems unlikely the exact same number of people in one precinct came out for two candidates, it happens. And if you don't account for it - your results will be messed up. \n",
    "\n",
    "method=dense means that the computer will assign the same rank to ties. So if the top two vote tallies are a tie, they will both have a 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling winners\n",
    "\n",
    "Now, let's filter only for rows where the rank is 1. If there are no ties, we should have only one row per precinct. So let's follow up our filter with a groupby that counts the number of rows there are per precinct, and plunks the answer into a new column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only rows where rank is 1\n",
    "winners = plv[plv['rank'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count rows per precinct\n",
    "winners['rows_per_precinct'] = winners.groupby('precinct_name')['precinct_name'].transform('count')\n",
    "winners.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...hold on, what is .transform? Why does this groupby look a little different than the others? \n",
    "\n",
    "Most of the time when you plunk the results of a groupby into an existing table as a new column, you'll need to use .transform(). You put the math function you want to do inside those parentheses - with quotes around it, just like you see here with 'count'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztAAy88eDggj"
   },
   "source": [
    "Finally, we will sort that new row so we can see any instances where there are more than 1 at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "y_h0dqu8A6_J",
    "outputId": "90fa212b-8937-4ab8-801a-3d855e2327fa"
   },
   "outputs": [],
   "source": [
    "#sort largest to smallest row count\n",
    "winners.sort_values('rows_per_precinct', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one tie. \n",
    "\n",
    "So now let's add a winner column. \n",
    "\n",
    "Enter the where statement. This might look something like an if/then statement if you've used those in Excel. Here, we are telling the computer that for every row rows_per_precint = 1, to place the corresponding candidate_name value in a new column called \"winner.\" If there is anything other than a 1 in the rows_per_precinct column, we're telling the computer to put \"TIE\" in that winner column.\n",
    "\n",
    "Pandas doesn't do where statements, but a library called numpy does. Just like we imported skimpy to do a little work outside the pandas wheelhouse, we'll import numpy here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for where statements, you need a library called numpy\n",
    "import numpy as np\n",
    "\n",
    "winners['winner'] = np.where((winners['rows_per_precinct'] == 1), (winners['candidate_name']), \"TIE\")\n",
    "winners.sort_values('rows_per_precinct', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning our data before we attach voter registration information\n",
    "\n",
    "To format this data so we don't have double rows for ties, you could drop the only column that contains differing values and then drop duplicates. Notice how, for our Pointe Precinct, candidate_name is the only column that makes the two rows different?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = winners.drop(columns =['candidate_name'])\n",
    "winners = winners.drop_duplicates()\n",
    "\n",
    "#write a sort by rows_per_precinct to make sure we have indeed gotten rid of our double precinct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bringing in the context\n",
    "\n",
    "Kari Lake lost her bid to be Arizona's governor because too many Republicans didn't like her. One way we can see that is by identifying areas that swung for Katie Hobbs despite having more registered Republicans than anything else.\n",
    "\n",
    "Follow the steps below to see if you can find out how many Republican-majority precincts went for Katie Hobbs. If you're feeling extra ambitious, see if you can find out how many Dem-majority precincts went for Kari Lake. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the voter_reg file\n",
    "voter_reg ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the first five rows of your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the voter_reg table to the winners table\n",
    "gov_race = \n",
    "gov_race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for majority Republican precincts\n",
    "rep = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by the winner column, and count how many precincts went for Hobbs and how many went for Kari\n",
    "my_groupby = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats! \n",
    "You've learned some Python data analysis fundementals. We hope you will continue to practice Python on the job and reach out to us if you have any questions! \n",
    "\n",
    "cmcglade@gannett.com\n",
    "\n",
    "sjayaraman@gannett.com"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
