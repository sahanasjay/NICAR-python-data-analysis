{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09a9329",
   "metadata": {},
   "source": [
    "#  Data analysis with Python \n",
    "\n",
    "Welcome! Caitlin McGlade and Sahana Jayaraman will guide you through using Python to find stories in data. We'll be using Jupyter Notebooks to execute commands. Jupyter is a popular opensource tool commonly used to explore data tables and organize code.\n",
    " \n",
    "You’ll learn:\n",
    "\n",
    "<ul> \n",
    "\n",
    "<li>How to pull data from both a file saved locally on your computer and directly from a website</li>\n",
    "\n",
    "<li>How to find “the most” or “the least” by sorting</li>\n",
    "\n",
    "<li>How to isolate or exclude variables with filtering</li>\n",
    "\n",
    "<li>How to compare variables with groupbys</li>\n",
    "\n",
    "<li>How to merge datasets</li>    \n",
    "</ul>\n",
    " \n",
    "This session is for people who have crunched numbers in Excel, or understand the concept of filtering, sorting and pivot tables /groupbys through other programs, and want to start analyzing data with Python so their work is more easily reproduceable. Or, those who have tried a little Python before and couldn’t get the hang of it but want to keep trying.\n",
    "\n",
    "## What are Jupyter notebooks? \n",
    "\n",
    "Jupyter notebooks allow you to organize your code and run it. The files you create automatically save as .ipynb files, which you can open in programs such as this one, Google Colab or other code management programs such as Sublime Text or Visual Studio Code. \n",
    "\n",
    "We like jupyter notebooks because they're free and provide a nice platform for clean note-taking. When creating a new cell, you can choose the format to be either code or notes by selecting the drop-down on the top of the page next to the Run commands. If you select Code, you can code. (placing a hashtag in front of anything in a code cell makes it a note.) If you select \"Markdown\" or \"Heading\", you can write notes using HTML formatting. (Double click in this cell to see how that looks. You can edit anything in these cells at any point.) \n",
    "\n",
    "## How do I get Jupyter on my computer?\n",
    "\n",
    "<a href=\"https://docs.anaconda.com/anaconda/index.html#:~:text=Anaconda%20is%20free%20and%20easy,Guide%20and%20then%20download%20Anaconda\">Download Anaconda Individual Edition.</a>\n",
    "    \n",
    "Once you have it on your computer, you can either access the notebooks by clicking on the green circle icon for Anaconda in your launchpad and then selecting the Jupyter Notebook icon or you can launch a terminal and simply write 'jupyter notebook' in your command line. \n",
    "\n",
    "## How do I run cells and create new ones? \n",
    "\n",
    "Whether you're writing notes or writing code, you'll hit shift then enter to run the cell. You can also hit the Run button on the top of the page. If you want to run your entire notebook at once, you can click the double arrows to the right of the Run button.\n",
    "\n",
    "You create new cells by either hitting the plus button at the top, next to the save button, or automatically by hitting shift-return if there is no cell below the one you're working in.\n",
    "\n",
    "You can delete cells with the scissor icon in the top left, but be careful. You can't undo that. \n",
    "\n",
    "## How do I find my .ipynb file and open it to continue working on it? \n",
    "\n",
    "You won't launch the program if you simply click on the .ipynb file from your finder window. Instead, you'll get a text file that will look like gobble-di-gook comparitively. Open your Jupyter notebook files by launching the application and using the directory that shows up on your browser. You can navigate through that directory as you would on your computer finder, but from here you can open the file in the notebook fomrat. File organization is important: You'll need to remember which folder you saved your notebook in to find it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea525b6",
   "metadata": {},
   "source": [
    "## Python libraries\n",
    "\n",
    "Python is a coding language that operates with a variety of libraries. Think of the libraries as toolkits. In order to run commands, you have to tell the computer which toolkit it needs to open to do the job. You'll come across a lot of these as you continue learning. \n",
    "\n",
    "These are only a handful of examples.\n",
    "\n",
    "<b>Pandas:</b> filtering, sorting, aggregating data (think pivot tables but in here they’re called ‘group bys’), math, merging datasets, appending datasets and more!\n",
    "\n",
    "<b>Geopandas:</b> analyze spatial files that feed into maps. Merging together two datasets based on the location of your records. Creates spatial files.\n",
    "\n",
    "<b>Numpy:</b> good for more complex math. Think if/then statements\n",
    "\n",
    "<b>Beautiful Soup:</b> good for scraping websites.\n",
    "\n",
    "In order to invoke a library you plan to use, you simply write \"import\" followed by the name of the library, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18f6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93654225",
   "metadata": {},
   "source": [
    "But you wouldn't want to stop there, because you will have to write out \"pandas\" every time you have a command that requires you to specifically call out the library you're using. If you're fine with that, cool, but we think that would get annoying.\n",
    "\n",
    "To rename the library to something simpler, you'd follow the above command with \"as pd\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd8bee5",
   "metadata": {},
   "source": [
    "You will do the same with these other libraries. \"import numpy as np\" or \"import geopandas as gpd\" for example.\n",
    "\n",
    "You can actually rename these things whatever you want. If you want to rename the panda \"henry,\" you could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as henry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169f424",
   "metadata": {},
   "source": [
    "... and the computer would understand that every time you bring up \"henry,\" you actually want it to invoke the pandas toolkit. We recommend you stick to pd though; it's pretty universal shorthand for pandas and you want your code to be easy for everyone to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9448efd",
   "metadata": {},
   "source": [
    "## Naming Things\n",
    "\n",
    "Get used to naming a lot of things when you're working with Python. Once something has a name, it's considered a variable.   \n",
    "\n",
    "A Python variable is a reserved memory location to store values. A variable can be a number, a list of numbers, a command, a dataframe, a column within that dataframe. You can name these variables whatever you want.\n",
    "\n",
    "Here are some rules about naming variables: \n",
    "\n",
    "<ul>\n",
    "<li>Variables must start with a letter</li> \n",
    "<li>No special characters</li> \n",
    "<li>Case sensitive</li>\n",
    "<li>No spaces, use underscores. \"ice cream\" would not work but \"ice_cream\" would</li> \n",
    "</ul>\n",
    "\n",
    "Once you assign a variable, you can use that name in future commands and the computer will understand that it represents the values you assigned to it. You do this by assigning a name, typing a single = and then following with whatever it represents. Always.\n",
    "\n",
    "For example, simply running \"2+2\" in the cell below will compute 4. But if I wanted to store that calculation and use it again to add to more things, I'd have to assign it as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5de8d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f6b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "math = 2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96813fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 + math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0efff4",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "\n",
    "The computer will read the contents of your columns from your data as either numbers or non-numbers. It's important to know what Python thinks each column is so that you can change it if you have to. \n",
    "\n",
    "<b> Abbreviations and their meanings: </b> \n",
    "\n",
    "<ul> \n",
    "\n",
    "<li><strong>str</strong>: short for \"string\", which is computer-speak for non-numbers </li>\n",
    "\n",
    "<li><strong>int</strong>: short for \"integer,\" which is a number with no decimal points.</li> \n",
    "\n",
    "<li><strong>float64</strong>: a number format with decimal points.</li>\n",
    "\n",
    "<li><strong>object</strong>: another way the program defines a string</li>\n",
    "\n",
    "<li><strong>bool</strong>: short for boolean, a datatype usually used to represent true or false values. Boolean datatypes must only contain two variables. </li>    \n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf349d",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "You'll usually start Jupyter notebooks by importing your libraries and bringing in the file you want to analyze. Remove the hashtag in front of the phrase \"import pandas as pd\" to import pandas and rename it as pd. \n",
    "\n",
    "(Oh, and P.S. -- putting hashtags in front of text or code create what we call \"comments,\" ways for you to make notes about your code or to stop specific lines/chunks of code from executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a6971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a comment in a code chunk. If you get rid of the hashtag in front of this text, your \n",
    "# code chunk will throw an error when you run it! \n",
    " \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97d47c",
   "metadata": {},
   "source": [
    "Next, we'll tell the computer what file we want to analyze. There are a few ways to do this, depending on the source of the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ace29f",
   "metadata": {},
   "source": [
    "# Grabbing a file from your computer\n",
    "\n",
    "You really can bring any type of file in and turn it into a dataframe you can analyze, but for this excercise we'll be working with the pd.read_csv function. \n",
    "\n",
    "The first step is making sure you know where the file lives in your computer. In this case, the file lives in the same folder as your Jupyter notebook. That means that you can simply write the command below and the program will find the file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "863e7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an officer-involved-shooting database from Phoenix\n",
    "#I have called it test\n",
    "elex = pd.read_csv('maricopa_county_elections_gen_2022.csv')\n",
    "elex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe61ab",
   "metadata": {},
   "source": [
    "This code defines the comma-separated file \"maricop_county_elections_gen_2022.csv\" as 'elex'. The syntax will always be like this, regardless of the file name, if you're simply importing a csv as it is. The file name goes in quotes, surrounded by parentheses. And don't forget the file extension! \n",
    "\n",
    "The same thing goes for excel files. If you had an excel file, you'd write the code below. \n",
    "\n",
    "df = pd.read_excel('file_name_here.xlsx')\n",
    "\n",
    "P.S. It's OK if you have a pink warning message after running the code above. This just means that the panda found a column with letters and numbers mixed together. This may matter if you intend to do math on that column or if you need to preserve leading zeroes.\n",
    "\n",
    "Pink warning messages like this one will always tell you which column has mixed datatypes, but it will use numbers rather than the name of the columns. Pandas counts things starting with 0 - so 0 is our first column.  \n",
    "\n",
    "Now that you've brought in your data, you can look at it with a .head() command. Unlike in Excel where you see the entire database on a screen, with this program you'll be only looking at slices. The .head() command will automatically give you the first five rows of your dataframe. If you want more than that, you can put your desired number inside the parenthese. df.head(10) would give you 10 rows, for example. \n",
    "\n",
    "You can also see a sample of your data with df.sample() - again you can put any number inside those parentheses to see however many rows you want - or see the last five rows of your data with  df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b7ab57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58805acd",
   "metadata": {},
   "source": [
    "<b>But what if the file didn't live in the same folder as this notebook?</b> \n",
    "    \n",
    "You'd need to write out directions so the panda can find the file. \n",
    "\n",
    "To do this, you can navigate to the finder window and find the file. At the very bottom of your finder window you should find a row of folders, indicating what the computer calls the path. Right click on the file name, and click \"copy as filename.\"\n",
    "\n",
    "If you're working on a Mac, you can also navigate to the file in your finder, control-click on it, then press the option key. That'll give you the option to copy the file's pathname.\n",
    "\n",
    "Then, paste the pathname into the parentheses between quotes.\n",
    "\n",
    "(The following is just an example; you'd need to replace them with the path on your computer.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57cf2ed",
   "metadata": {},
   "source": [
    "df = pd.read_csv('/Users/cmcglade/Documents/nicar-training/maricopa_county_elections_gen_2022.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ddfcc",
   "metadata": {},
   "source": [
    "# Grabbing a file straight from the internet\n",
    "\n",
    "A lot of government data portals post a link to the file on their webpages so that you can directly grab the file with code instead of downloading it to your computer and then opening it. We recommend grabbing the file straight from the website if the file is routinely updating.\n",
    "\n",
    "## Step One: Import your libraries\n",
    "\n",
    "\"Request\" and \"urlopen\" are toolkits you can invoke if you want to yank data from a website. Go ahead and run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf15754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3430d",
   "metadata": {},
   "source": [
    "## Step Two: Write the request\n",
    "To call on the link, we use the command Request(). But if we simply write Request('link.csv'), then we haven't assigned it to a variable so we can't do much with it.  \n",
    "\n",
    "So req = Request('link_goes_here.csv') allows us to tell the computer that we're going to grab the link, and call it req. You could call it whatever you'd like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd431336",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = Request('https://elections.maricopa.gov/asset/jcr:90b6d508-3b2b-472a-96ad-846ad21844f7/ArizonaExportByPrecinct_11082022_11212022.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810751a1",
   "metadata": {},
   "source": [
    "Some websites block requests from certain browsers. If we try to just access this link using python alone, we'll likely get a restriction error. The way around that is to tell the website that our user agent is Mozilla/5.0 so it thinks the request is coming from a web browser, and allows us in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5763b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "req.add_header('User-Agent', 'Mozilla/5.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe53de",
   "metadata": {},
   "source": [
    "P.S: There are multiple ways to make this request + get to the same place! What we're showing you is just one of them. Libraries like requests, io and pandas can all help you tranform data that lives in a file online into a dataframe you can work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d318fc",
   "metadata": {},
   "source": [
    "## Step Three: Tell the computer what to do with the request\n",
    "\n",
    "Now we have to tell the computer to open the url, and assign it to a variable. In this case, I'm calling it content. I've written content after the command so that I can see what content looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d49e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = urlopen(req)\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78964a7",
   "metadata": {},
   "source": [
    "As you can see, we aren't able to treat the file as a dataframe yet. In order to do that, we have to tell the computer to read 'content' as a csv.\n",
    "\n",
    "Here, we are telling the computer to read 'content' as a csv, and call it 'df'. (short for dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ab3df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(content, sep='\\t', \n",
    "                 lineterminator='\\r', encoding=\"latin-1\", \n",
    "                 dtype={'ï»¿ContestId': str, 'CandidateId': str})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9e483",
   "metadata": {},
   "source": [
    "OK, let's break this down. \n",
    "\n",
    "<b>sep='\\t'</b> tells the computer that our data is separated by tabs\n",
    "\n",
    "<b>lineterminator='\\r'</b> tells the computer to create a new row when it reaches a new line in the file. The computer understands \\r to mean \"new line\"\n",
    "\n",
    "<b>encoding=\"latin-1\"</b> tells the computer how the file is encoded. \n",
    " \n",
    " ... but what is encoding? Well, what shows up as letters — text — on your screen isn't stored as letters in your file. Instead, it's stored as numeric values that your computer translates into the letters you see based on an encoding standard. An encoding standard is a scheme that assigns character sets numeric values. Different encoding standards use different character sets — different languages use different characters, so there are many different characters. The Unicode encoding system accomodates most character sets across multiple languages. \n",
    "\n",
    "<b>dtype={'ï»¿ContestId': str, 'CandidateId': str})</b> tells the computer that those two columns need to be read as text. (str is short for string, which is computer-speak for non-number characters.) Remember the pink warning message? This addresses that. \n",
    "\n",
    "Any time you need to specify datatype when bringing in a file, you can write it like this. Your column name goes in quotes or single quotes, followed by a colon, followed by your desired datatype. Be sure to surround this information with curly braces. {}\n",
    "\n",
    "We are specifying that we want these columns to be read as strings because they contain digits that might start with leading zeros. The computer will automatically assume columns that solely have numbers in them as numbers - and that means if we have leading zeros, the computer will remove those zeros. The leading zeros may be important if 0123 and 123 are two different contests. Without telling the computer that the columns should be read as text, those two contests would look like the same one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3c377",
   "metadata": {},
   "source": [
    "# Step Four: Clean column names\n",
    "\n",
    "Okay, I know you noticed those gnarly column names. Like, wtf are those weird characters before Contest_ID?? \n",
    "\n",
    "Don't worry, there's an easy way to standardize your column names in Python. Standardizing your column names is important because it'll make your analysis down the line that much easier: No need to remember whether any particular column was capitalized, and no need to deal with funky spacing. \n",
    "\n",
    "To make our column names a little more palatable, we'll be using a Python library called Skimpy. Skimpy is good for a lot of stuff; it can help you produce easy summary stats from pandas dataframes. It also has a clean_columns functionality, which will get rid of weird characters, lowercase all your column names and change weird spacing into neat underscores. Delete the hadshtage in the block of code below and run it to see Skimpy in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfdfecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import clean_columns\n",
    "\n",
    "df_clean = clean_columns(df)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c1b51",
   "metadata": {},
   "source": [
    "## Step Five: Save a local copy\n",
    "You should always do this when you're pulling data from a website in case the server goes down, data gets deleted or you want to time-stamp your data to keep track of changes during updates.   \n",
    "\n",
    "Below, I'm sending our dataframe 'df' to a  csv file to live forever in the computer, and I'm calling the file 'elections_03_02_23.csv'. If I did this same thing tomorrow, I'd call it 'elections_03_03_23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba1e47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('elections_03_02_23.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
